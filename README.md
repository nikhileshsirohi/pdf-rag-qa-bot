# üìÑ PDF RAG QA Bot

A **Retrieval-Augmented Generation (RAG)** system that allows users to upload PDF documents once and then ask **unlimited questions** about their content using semantic search and large language models.

This project demonstrates how to build a **local, reusable, and scalable RAG pipeline** instead of sending entire PDFs as prompts to LLMs.

---

## ‚ú® Features

- üì§ Upload PDF documents (single or multiple over time)
- ‚úÇÔ∏è Automatic text extraction and chunking
- üß† Semantic search using embeddings
- ‚ö° Fast similarity search using **FAISS (Facebook AI Similarity Search)**
- ü§ñ Answer generation using multiple LLM providers
- ‚ôªÔ∏è Persistent vector store (reuse indexed PDFs without re-uploading)
- üåê Simple browser-based UI

---

## üß± Tech Stack

- **Python**
- **FastAPI** ‚Äì backend API
- **FAISS (Facebook AI Similarity Search)** ‚Äì vector indexing & search
- **Hugging Face Transformers**
- **Sentence Transformers**
- **OpenAI / Gemini (optional via API key)**
- **HTML + JavaScript** ‚Äì lightweight UI

---

## üöÄ Getting Started

### 1Ô∏è‚É£ Clone the repository
```bash
git clone https://github.com/nikhileshsirohi/pdf-rag-qa-bot.git
cd pdf-rag-qa-bot
pip install -r requirements.txt
```
***Start the backend server***
```bash
uvicorn api.main:app --reload
```
***FastAPI docs:***
```bash
http://127.0.0.1:8000/docs
```
**Start the UI**
***Open the UI file***
ui/index.html

## What is this project about?

This project allows you to ask questions from any PDF document you upload.

You can:
- ***Upload a PDF only once***
- ***Ask unlimited questions anytime***
- ***Add more PDFs later (index grows incrementally)***
- ***Reuse the same indexed knowledge every time***

There is no need to upload the same file again.

‚∏ª

### Why not upload PDFs directly to ChatGPT or Gemini?

Uploading PDFs directly to an LLM is not scalable:
- ‚ùå Prompt size limitations
- ‚ùå Entire document must be sent every time
- ‚ùå Expensive and inefficient
- ‚ùå No persistent memory

### How this project is different
- ***PDFs are not passed as prompts***
- ***Documents are converted into vector embeddings***
- ***Only relevant chunks are retrieved***
- ***Context size stays small and efficient***
- ***Knowledge is persistent and reusable***

‚∏ª

## How it works (RAG Pipeline)

### 1Ô∏è‚É£ PDF Ingestion
- ***User uploads a PDF***
- ***Text is extracted from the document***
- ***Text is split into semantic chunks (paragraph-sized)***

‚∏ª

### 2Ô∏è‚É£ Embedding Generation

Each chunk is converted into a vector embedding using: ***sentence-transformers/all-MiniLM-L6-v2***

#### What are embeddings?
- Dense numerical representations of text
- Semantically similar text ‚Üí vectors closer in space
- Generated using transformer internals:
- input_ids ‚Äì token IDs
- - attention_mask ‚Äì mask for valid tokens
- - Encoder hidden layers
- - Output: fixed-size vector (384 dimensions)

### 3Ô∏è‚É£ Vector Storage using FAISS

FAISS (Facebook AI Similarity Search) is used to store and search embeddings.
	‚Ä¢	Each embedding is assigned an index automatically
	‚Ä¢	Corresponding text chunks are stored at the same index
	‚Ä¢	Cosine similarity is used for semantic search
	‚Ä¢	FAISS index is persisted to disk

This allows reuse across application restarts.

### 4Ô∏è‚É£ Question Answering (Search + Generation)

When a user asks a question:
	1.	Question is converted into an embedding
	2.	FAISS retrieves top-K most similar embeddings
	3.	Matching chunk indices are mapped back to text
	4.	Relevant chunks are passed to an LLM
	5.	LLM refines the context and generates the final answer

## Supported LLMs

### Free (Default)
	‚Ä¢	Hugging Face
	‚Ä¢	google/flan-t5-base
	‚Ä¢	No API key required

‚∏ª

### Optional (Requires API Key)

**Google Gemini**
	‚Ä¢	models/gemini-flash-lite-latest
	‚Ä¢	models/gemini-flash-latest
	‚Ä¢	models/gemini-pro-latest

**OpenAI**
	‚Ä¢	gpt-4o-mini
	‚Ä¢	gpt-4o

Users can select the model from the UI.
If no API key is provided, the system automatically falls back to the free Hugging Face model.

### Persistent Knowledge Base
	‚Ä¢	PDFs are uploaded only once
	‚Ä¢	FAISS index and text metadata are saved locally
	‚Ä¢	Knowledge is reused across sessions
	‚Ä¢	No repeated uploads required


## Author

### Nikhilesh Sirohi
**GitHub: https://github.com/nikhileshsirohi**